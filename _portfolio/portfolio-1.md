---
title: "Etu{d,b}e"
excerpt: "Performance setup in collaboration with Tommy Davis and aotonomous musical agents. <br/><img src='/images/tube.jpeg'>"
collection: portfolio
---

The DYCI2 project is currently developed at IRCAM and aims to design “generative agents and tools for smart composition and human-machine co-improvisation.” We will be using a set of software built in Max/MSP based on this library. Different strategies are used to provide a meaningful improvisation context; “reactive listening and anticipatory behaviour regarding a temporal specification (or scenario)” (Nika 2017). With the existing interface, we have already performed simple musical ideas. An example can be seen following this link (https://youtu.be/oUbeL_lAhFU)
Currently, the real-time performance controls over the agent are limited. In collaboration with  IRCAM research team members, we will enable more intricate interaction with the machine. This implies a better control over multiple parameters and multimodal feedback related to the status and controls of the patch via visual indicators (screen or LED), to inform the instrumentist about the patch during an improvisation.

Once those controls over the musical agent are implemented with the graphical interface of Max/MSP or with computer input interface (keyboard, mouse, MIDI controller), we will start working on more complex scenarios. However, we think that in an ideal context, the performer should be able to interact directly with specific parameters of the musical agent.
Towards this goal, we will develop a digital interface fixed onto a saxophone, which will send data to the patch for further processing. The design of similar digital musical instruments (DMI) and various forms of meta- or augmented-instrument is not new and our work is directly inspired by the work done by researchers at IDMIL [EDU, JOHNNY] and elsewhere.
For a first prototype, we envision to model and 3D print the body of the controller. This would offer flexibility in terms of design and ease the development process. Custom electronics based around the esp8266 (WIFI enabled Arduino-like boards), or similar sensors, will be embedded in the model. We will explore uncommon inputs and multimodal feedback later in the process and based on our initial tests.

In addition to the saxophone, we will work with an unusual instrument: a tube with a saxophone mouthpiece attached. The tube was originally conceived with John Bower’s ‘infra-instrument’ concept in mind, that is, an instrument which is restricted in its expressivity, broken or only a portion of a standard instrument, and limited in virtuosic technique (Bowers, 2005). These infra-instruments, “precisely by virtue of their producing degenerate or simplistic tonalities, can work very well with live processing or computer-derived parts – more spectral-temporal latitude is available for augmentation” (Bowers, 2005). The plastic tube with a saxophone mouthpiece is a basic design which is appealing for our purposes since it offers more liberty for augmentation with electronics. It has a raw sound which is limited in many regards yet intriguing and demands creative solutions to develop suitable electronics. The saxophone mouthpiece allows the performer to maintain a high level of control over the sound production, articulations, and dynamics developed from years of musical training. The cylindrical tube reacts differently than the conical saxophone producing inharmonic sounds, overtones, and complex textures, thus it presents control challenges for saxophonists.

The inspiration for this project stemmed from a collaboration for Tommy’s DMus recital performance of the DYCI2 modules with saxophone planned for May 2021. In 2019, Vincent attended the performance Reverberant House, where Tommy improvised with tubes and saxophones alongside his Duo d’Entre-Deux. These two events were the impetus to create a project utilizing the tube, the DYCI2 modules, a custom interface, and improvisation. The project represents each collaborators expertise and interests equally. Vincent brings his expertise as programmer, instrument builder, interface designer, and réalisateur en informatique musical. Tommy will contribute his proficiency as improviser, performer of electronic and interactive music, and collaborator co-designer of the improvising modules.

We have a preliminary budget for resources needed for this project including 3D printer machine time, 3D printer materials, haptic sensors, wiring, plastic tubing, wifi module, LEDs and or feedback screens.

